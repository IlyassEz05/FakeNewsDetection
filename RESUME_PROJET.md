# ðŸ“‹ RÃ©sumÃ© Complet du Projet - DÃ©tection de Fausses Nouvelles

## ðŸŽ¯ Objectif du Projet

CrÃ©er une application web complÃ¨te pour dÃ©tecter les fausses nouvelles en utilisant la **similaritÃ© sÃ©mantique** entre une information fournie par l'utilisateur et une base de donnÃ©es d'articles de presse vÃ©rifiÃ©s.

## ðŸ—ï¸ Architecture du Projet

```
fakenewsdetection/
â”œâ”€â”€ backend/                    # API FastAPI
â”‚   â”œâ”€â”€ main.py                # Serveur FastAPI + endpoint /analyze
â”‚   â”œâ”€â”€ db.py                  # Connexion MongoDB
â”‚   â”œâ”€â”€ vector_search.py       # Recherche vectorielle + re-ranking
â”‚   â””â”€â”€ requirements.txt       # DÃ©pendances Python
â””â”€â”€ frontend/                   # Interface web
    â”œâ”€â”€ index.html             # Page principale
    â”œâ”€â”€ style.css              # Styles CSS
    â””â”€â”€ script.js              # Logique JavaScript
```

## ðŸ—„ï¸ Base de DonnÃ©es MongoDB

### Configuration
- **Base de donnÃ©es** : `elbotola`
- **Collection actualitÃ©s** : `wydad_news` (3000 articles)
- **Collection vectorisations** : `wydad_vector` (6004 vectorisations)
  - 2 versions par article : titre franÃ§ais + titre anglais
  - Chaque document contient : `_id`, `url`, `language`, `text`, `embedding` (384 dimensions), `created_at`

### Structure des DonnÃ©es

**wydad_news** (articles complets) :
```json
{
  "_id": ObjectId,
  "title_ar": "titre arabe",
  "title_fr": "titre franÃ§ais",
  "title_en": "titre anglais",
  "url": "https://...",
  "pub_date": timestamp,
  "image": "url_image",
  "tags": "tags",
  "scraped_at": "date"
}
```

**wydad_vector** (vectorisations) :
```json
{
  "_id": ObjectId,
  "url": "https://...",
  "language": "fr" ou "en",
  "text": "titre de l'article",
  "embedding": [384 floats],
  "created_at": ISODate
}
```

## ðŸ” Comment Fonctionne la Recherche SÃ©mantique

### 1. ModÃ¨le d'Embedding

**ModÃ¨le utilisÃ©** : `all-MiniLM-L6-v2` (384 dimensions)
- ModÃ¨le sentence-transformers
- Convertit le texte en vecteur numÃ©rique (embedding)
- MÃªme modÃ¨le utilisÃ© pour crÃ©er les embeddings dans MongoDB

### 2. Processus de Recherche (3 Ã‰tapes)

#### Ã‰tape 1 : Recherche TOP-K par SimilaritÃ© Cosinus

```python
# 1. GÃ©nÃ©rer l'embedding de la requÃªte utilisateur
query_embedding = model.encode("wydad a signÃ© hakim ziyech")

# 2. Charger tous les embeddings de wydad_vector
# 3. Calculer la similaritÃ© cosinus pour chaque embedding
score = dot_product(query_embedding, doc_embedding) / (norm1 * norm2)

# 4. Trier par score dÃ©croissant
# 5. Prendre les TOP-20 meilleurs rÃ©sultats
```

**SimilaritÃ© Cosinus** :
- Mesure l'angle entre deux vecteurs
- Score entre -1 et 1 (gÃ©nÃ©ralement entre 0 et 1 pour des embeddings)
- Plus le score est proche de 1, plus les textes sont sÃ©mantiquement similaires

#### Ã‰tape 2 : Extraction d'EntitÃ©s

Pour chaque rÃ©sultat TOP-20, on extrait :
- **Joueurs** : Hakim Ziyech, Aziz Ki, Regragui, etc.
- **Clubs** : Wydad, Raja, WAC, etc.
- **Actions** : signÃ©, rejoint, gagnÃ©, buteur, etc. (FR/EN)

#### Ã‰tape 3 : Re-ranking avec Score Hybride

**Formule du score final** :
```
score_final = 0.6 Ã— cosine_score + 0.3 Ã— entity_score + 0.1 Ã— keyword_score
```

**Composantes** :
- **cosine_score** (60%) : SimilaritÃ© sÃ©mantique vectorielle
- **entity_score** (30%) : Correspondance des entitÃ©s (joueurs, clubs, actions)
- **keyword_score** (10%) : Chevauchement de mots-clÃ©s significatifs

**Avantage** : Le re-ranking permet de trouver l'article le plus pertinent mÃªme si la similaritÃ© cosinus seule n'est pas parfaite.

### 3. DÃ©cision Finale

**Seuils de verdict** :
- **score > 0.60** â†’ "Information probablement vraie"
- **0.40 â‰¤ score â‰¤ 0.60** â†’ "Information incertaine"
- **score < 0.40** â†’ "Information probablement fausse"

## âŒ Index Vectoriel MongoDB

### RÃ©ponse : NON, nous n'avons PAS crÃ©Ã© d'index vectoriel

**Pourquoi ?**

L'index vectoriel `$vectorSearch` de MongoDB est **uniquement disponible sur MongoDB Atlas** (version cloud payante), pas sur MongoDB local.

**Votre configuration** :
- âœ… MongoDB local (MongoDB Compass)
- âœ… Base de donnÃ©es : `elbotola`
- âœ… Collection : `wydad_vector` avec embeddings

**Ce que nous avons fait Ã  la place** :

**Recherche vectorielle manuelle en Python** :
```python
# 1. Charger tous les embeddings depuis MongoDB
all_vectors = collection.find({}, {"embedding": 1, ...})

# 2. Calculer similaritÃ© cosinus pour chaque embedding
for doc in all_vectors:
    score = cosine_similarity(query_embedding, doc['embedding'])
    
# 3. Trier par score et prendre TOP-20
results.sort(key=lambda x: x['score'], reverse=True)
top_20 = results[:20]
```

**Avantages** :
- âœ… Fonctionne avec MongoDB local (gratuit)
- âœ… Pas besoin de MongoDB Atlas
- âœ… ContrÃ´le total sur le processus
- âœ… Compatible avec votre setup actuel

**InconvÃ©nients** :
- âš ï¸ Plus lent (charge tous les 6004 embeddings Ã  chaque requÃªte)
- âš ï¸ Consomme plus de mÃ©moire

### Si vous voulez utiliser un Index Vectoriel (Optionnel)

**Option 1 : MongoDB Atlas** (pour production)
```javascript
// CrÃ©er un index vectoriel dans MongoDB Atlas
db.wydad_vector.createSearchIndex({
  "name": "news_vector_index",
  "definition": {
    "mappings": {
      "dynamic": false,
      "fields": {
        "embedding": {
          "type": "knnVector",
          "dimensions": 384,
          "similarity": "cosine"
        }
      }
    }
  }
})
```
- **Avantage** : Recherche ultra-rapide (indexÃ©e)
- **InconvÃ©nient** : NÃ©cessite MongoDB Atlas (payant)

**Option 2 : FAISS** (bibliothÃ¨que Python)
- CrÃ©er un index en mÃ©moire au dÃ©marrage
- Recherche trÃ¨s rapide
- NÃ©cessite de modifier le code pour charger FAISS

## ðŸš€ FonctionnalitÃ©s ImplÃ©mentÃ©es

### Backend (FastAPI)

1. **Endpoint `/analyze`** (POST)
   - ReÃ§oit un texte Ã  analyser
   - DÃ©tecte automatiquement la langue (FR/EN)
   - GÃ©nÃ¨re l'embedding du texte
   - Recherche les articles similaires
   - Applique le re-ranking
   - Retourne verdict, score, article le plus proche

2. **PrÃ©chargement du modÃ¨le**
   - Le modÃ¨le sentence-transformers est chargÃ© au dÃ©marrage
   - Ã‰vite le dÃ©lai au premier appel

3. **Gestion des erreurs**
   - Validation des entrÃ©es
   - Gestion des erreurs MongoDB
   - Messages d'erreur clairs

### Frontend (HTML/CSS/JS)

1. **Interface utilisateur**
   - Design moderne avec dÃ©gradÃ© violet/bleu
   - Zone de texte pour saisir l'information
   - Bouton d'analyse avec loader
   - Affichage des rÃ©sultats (verdict, score, article)

2. **ExpÃ©rience utilisateur**
   - Message de chargement informatif
   - Barre de score animÃ©e
   - Gestion des erreurs
   - Responsive (mobile-friendly)

## ðŸ“Š Flux de DonnÃ©es Complet

```
Utilisateur saisit: "wydad a signÃ© hakim ziyech"
         â†“
Frontend envoie POST /analyze
         â†“
Backend:
  1. DÃ©tecte langue: "fr"
  2. GÃ©nÃ¨re embedding (384 dimensions)
  3. Charge tous les embeddings de wydad_vector (6004)
  4. Calcule similaritÃ© cosinus pour chaque embedding
  5. Trie et prend TOP-20
  6. Extrait entitÃ©s de la requÃªte: {joueurs: ["hakim ziyech"], clubs: ["wydad"], actions: ["signÃ©"]}
  7. Pour chaque TOP-20:
     - Extrait entitÃ©s du document
     - Calcule entity_score
     - Calcule keyword_score
     - Calcule score_final = 0.6Ã—cosine + 0.3Ã—entity + 0.1Ã—keyword
  8. Trie par score_final dÃ©croissant
  9. Retourne le meilleur rÃ©sultat
         â†“
Frontend affiche:
  - Verdict: "Information probablement vraie" (si score â‰¥ 0.75)
  - Score: 0.8234 (82.34%)
  - Article le plus proche: "Wydad signe Hakim Ziyech..."
  - URL source
```

## ðŸ”§ Technologies UtilisÃ©es

- **Backend** : FastAPI, Python 3.9+
- **Base de donnÃ©es** : MongoDB local
- **Embeddings** : sentence-transformers (all-MiniLM-L6-v2)
- **Calculs** : NumPy (similaritÃ© cosinus)
- **Frontend** : HTML, CSS, JavaScript vanilla
- **DÃ©tection de langue** : langdetect

## âš¡ Performance

- **Temps de rÃ©ponse** : 3-8 secondes par requÃªte
  - GÃ©nÃ©ration embedding : 500ms - 2s
  - Recherche dans 6004 embeddings : 1-3s
  - Re-ranking : 500ms - 1s
  - Lookup MongoDB : 500ms - 1s

- **Optimisations** :
  - ModÃ¨le prÃ©chargÃ© au dÃ©marrage
  - Calculs vectorisÃ©s avec NumPy
  - TOP-K limitÃ© Ã  20 pour le re-ranking

## ðŸŽ“ Approche AcadÃ©mique

Le systÃ¨me **n'affirme pas la vÃ©ritÃ© absolue**. Il Ã©value la **plausibilitÃ©** d'une information en :
1. Comparant avec des articles existants dans la base
2. Calculant un score de similaritÃ© sÃ©mantique
3. Donnant un verdict probabiliste basÃ© sur le score

**Principe** : Si une information est trÃ¨s similaire Ã  un article vÃ©rifiÃ© dans la base, elle est probablement vraie. Si elle n'a pas de correspondance, elle est probablement fausse.

## ðŸ“ Points Importants

1. **ModÃ¨le d'embedding** : Doit Ãªtre le mÃªme que celui utilisÃ© pour crÃ©er les embeddings
2. **Pas d'index vectoriel** : Utilisation de recherche manuelle (MongoDB local)
3. **Re-ranking** : AmÃ©liore significativement la prÃ©cision
4. **Extraction d'entitÃ©s** : Permet de mieux comprendre le contexte (joueurs, clubs, actions)

## ðŸš€ Pour DÃ©marrer

```bash
# Backend
cd backend
python3 -m uvicorn main:app --host 0.0.0.0 --port 8000 --reload

# Frontend
cd frontend
python3 -m http.server 8080

# AccÃ©der Ã  l'application
http://localhost:8080
```

